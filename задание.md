Техническое задание (ТЗ)

1. Общая информация

Название проекта:
Дообучение трансформерной модели для машинного перевода математических текстов (EN ↔ RU)

Тип работы:
Курсовая работа (2 курс бакалавриата)

Область:
Машинное обучение, NLP, машинный перевод, специализированные языки (математический язык)

Уровень сложности:
Бакалавр (без требований к разработке новой архитектуры, фокус на корректном применении и анализе)

⸻

2. Цель и задачи проекта

2.1 Цель

Создать и дообучить трансформерную модель, способную качественно переводить математические тексты между двумя естественными языками (например, EN → RU), сохраняя:
	•	математический смысл,
	•	корректность формул,
	•	структуру доказательств и определений,
	•	терминологическую точность.

2.2 Основные задачи
	1.	Проанализировать существующие трансформерные модели для машинного перевода.
	2.	Выбрать базовую pretrained-модель.
	3.	Подобрать или сформировать специализированный математический датасет.
	4.	Разработать пайплайн предобработки математических текстов.
	5.	Дообучить модель на выбранном датасете.
	6.	Оценить качество перевода с использованием общих и специализированных метрик.
	7.	Проанализировать ошибки и ограничения модели.

⸻

3. Описание предметной области

3.1 Характеристика математического языка

Математические тексты отличаются от обычного естественного языка тем, что:
	•	содержат формулы (LaTeX / MathML),
	•	используют строгую терминологию,
	•	имеют сложную логическую структуру (теоремы, леммы, доказательства),
	•	требуют точности, а не семантической «приближённости».

3.2 Типы входных данных
	•	Учебники по математике
	•	Научные статьи
	•	Конспекты лекций
	•	Описания алгоритмов

⸻

4. Требования к данным (Dataset)

4.1 Формат данных
	•	Параллельный корпус текстов (source → target)
	•	Формулы представлены в LaTeX
	•	Формат хранения:
	•	JSON / CSV / TSV
	•	Структура:

{
  "source": "Let $f(x)$ be a continuous function...",
  "target": "Пусть $f(x)$ — непрерывная функция..."
}



4.2 Источники данных (рекомендуемые для курсовой)

Основной датасет (рекомендуется):
	1.	OPUS — WikiMatrix (EN–RU)
	•	Параллельный корпус из Википедии
	•	Содержит большое количество научных и полуформальных текстов
	•	Подходит как базовый корпус
	2.	OPUS — GNOME / Ubuntu / KDE (EN–RU)
	•	Технические тексты с формальной лексикой
	•	Полезны для дообучения терминологии
	3.	arXiv Math (самостоятельно собранный, опционально)
	•	Математические статьи на английском
	•	Используются как monolingual corpus (опционально)

Выбранная стратегия для курсовой:
Использовать WikiMatrix EN–RU как основной датасет и дополнительно отфильтровать предложения, содержащие математические формулы или математическую лексику.

4.3 Объём данных

Объём данных
	•	Минимум: 50–100 тыс. пар предложений
	•	Желательно: 300 тыс. – 1 млн

⸻

5. Предобработка данных

5.1 Очистка данных
	•	Удаление битых формул
	•	Удаление слишком длинных или коротких примеров
	•	Нормализация пробелов и спецсимволов

5.2 Работа с формулами (важно)

Возможные подходы:
	1.	Сохранение формул как токенов
	•	Формулы не переводятся
	•	Пример: <FORMULA_1>
	2.	Обучение модели переводить текст вокруг формул
	3.	Гибридный подход (рекомендуется)

5.3 Токенизация
	•	SentencePiece / BPE
	•	Совместный словарь для обоих языков
	•	Учёт математических символов (\sum, \int, \forall)

⸻

6. Модель

6.1 Базовая архитектура

Трансформер encoder-decoder

6.2 Возможные pretrained-модели
	•	MarianMT
	•	mBART
	•	T5
	•	NLLB (если позволяет вычислительный бюджет)

6.3 Причина выбора

Модель должна:
	•	поддерживать seq2seq
	•	иметь доступ к весам
	•	быть совместимой с HuggingFace Transformers

⸻

7. Обучение

7.1 Подход
	•	Fine-tuning pretrained модели
	•	Заморозка части слоёв (опционально)

7.2 Гиперпараметры (начальные)
	•	Batch size: 8–32
	•	Learning rate: 2e-5 – 5e-5
	•	Optimizer: AdamW
	•	Epochs: 3–10
	•	Warmup steps: 5–10%

7.3 Аппаратные требования
	•	GPU с 8–16 GB VRAM (минимум)
	•	Возможность mixed precision (fp16)

⸻

8. Оценка качества

8.1 Автоматические метрики
	•	BLEU
	•	chrF
	•	TER

8.2 Специализированная оценка
	•	Сохранение формул без искажений
	•	Корректность математических терминов
	•	Ручная экспертная оценка (10–20 примеров)

⸻

9. Анализ ошибок
	•	Ошибки в терминах
	•	Потеря логической связности
	•	Нарушение структуры доказательств
	•	Искажение формул

⸻

10. Ожидаемые результаты
	•	Обученная модель машинного перевода
	•	Скрипты предобработки и обучения
	•	Отчёт с экспериментами и метриками
	•	Примеры успешных и неуспешных переводов

⸻

11. Возможные улучшения (если останется время)
	•	Добавление contrastive learning
	•	Мультиязычное обучение
	•	Использование синтетических данных
	•	Специальный loss для формул

⸻

12. Стек технологий
	•	Python
	•	PyTorch
	•	HuggingFace Transformers
	•	SentencePiece
	•	LaTeX

⸻

13. Критерии успешности курсовой работы
	•	Модель обучается без ошибок
	•	Улучшение метрик по сравнению с baseline
	•	Корректная обработка формул
	•	Воспроизводимость экспериментов

⸻

Примечание:
Данное ТЗ может использоваться как промпт для ИИ-помощника или как основа для пояснительной записки курсовой работы.